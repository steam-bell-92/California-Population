# -*- coding: utf-8 -*-
"""California_housing_train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11_iQ4PQkMyEtj6-glVxnvMTEu9mjloOI

## ***EXPLORATORY DATA ANALYSIS (EDA)***

## Importing all required libraries for EDA
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

"""# Reading the .csv file"""

df = pd.read_csv('/content/sample_data/california_housing_train.csv')
df.head()

"""# Getting Basic Information

Checking the size of dataset
"""

df.shape

"""Reindexing the dataset"""

df.index = range(1,len(df) + 1)
df.head()

""" # More basic information about dataset"""

df.describe()

"""More information"""

df.info()

"""Average of median house values of Houses with population greater than 750 (inclusive)"""

df[(df['population'] >= 750)]['median_house_value'].mean()

""" Names of columns"""

df.columns

"""# Intoducing a new parameter : 'Number of rooms per Household'"""

df['room/household'] = df['total_rooms'] / df['households']
df.head()

"""Calculating total null value rows"""

df.isnull().sum()

"""# Removing Outliners using IQR method"""

datas = ['median_income', 'median_house_value', 'households', 'population', 'total_bedrooms', 'total_rooms', 'housing_median_age', 'room/household']

for i in datas :
  Q1 = df[i].quantile(0.25)
  Q3 = df[i].quantile(0.75)
  IQR = Q3 - Q1
  lower_bound = Q1 - 1.5 * IQR
  upper_bound = Q3 + 1.5 * IQR
  df1 = df[(df[i] >= lower_bound) & (df[i] <= upper_bound)]

df1.shape

"""Calculating number of outliners"""

outliners = len(df) - len(df1)
outliners

"""# An KDE Plot between "rooms per household" vs "total rooms"
"""

plt.figure(figsize=(10, 6))
sns.kdeplot(x='room/household', y='total_rooms', data=df, fill=True, thresh = 0.0005)
sns.kdeplot(x='room/household', y='total_rooms', data=df1, fill=True, thresh = 0.0005)
plt.title('KDE Plot used to visualize the changes made due to removal of outliners')
plt.show()

"""I have plotted this KDE Plot to compare pre & post conditions due to removal outliners using IQR method

# Histogram of "Housing Median Age" vs "Median Income"
"""

sns.histplot(x='housing_median_age', y='median_income', data = df1, cmap='coolwarm', cbar = True)
plt.title('Histogram of Housing Median Age vs Median Income')
plt.show()

"""I know it looks more like heatmap but its histogram

We may see that there is a major chunk of houses with median income betweeen 2 - 4

# Plotting a Regplot to observe trend of Housing Median Age w.r.t Median House Value
"""

sns.regplot(x=df1['housing_median_age'].head(100) , y=df1['median_house_value'].head(100) , scatter=True, order = 3)
plt.title('Regplot of Housing Median Age vs Median House Value')
plt.show()

"""The Regplot shows median house value monotonically decreasing as median age of house increase

This implies that more newer the house more is its value or older the house lesser its value

# A Correlation matrix
"""

sns.heatmap(df1.corr(), cmap='coolwarm', cbar=True, annot=True)
plt.title('Correlation Matrix')
plt.show()

sns.histplot(df1['median_house_value'], kde=True, bins=30)
plt.title("Distribution of Median House Value")
plt.show()

plt.figure(figsize=(10, 6))
plt.scatter(df1['longitude'], df1['latitude'], c=df1['median_house_value'], cmap='viridis', alpha=0.4)
plt.colorbar(label='Median House Value')
plt.title('Housing Prices by Location in California')
plt.show()

"""Its not a geographical plot but gives idea of where are the major big cities in Calfornia:
- (33, -118) approximate
- (37, -122.5) approximate
"""

import plotly.express as px

fig = px.scatter_mapbox(df, lat="latitude", lon="longitude", color="median_house_value", color_continuous_scale="Portland", size_max=15, zoom=5, height=600, title="California Housing Prices on Map", opacity=0.5)
fig.update_layout(mapbox_style="open-street-map")
fig.show()

"""Location is written as (latitude, longitude)

# ***Machine Learning***

# Importing all libraries for prediction model
"""

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import r2_score
from sklearn.preprocessing import RobustScaler
from sklearn.linear_model import LinearRegression

"""# Splitting dataset into training data (80%) & testing data (20%)"""

cols = ['population','total_bedrooms','room/household']
X = df1.drop(cols, axis=1)
y = df1['population']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Feature Transforming (Scaling)"""

scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""Fitting and predicting model"""

model = LinearRegression()
model.fit(X_train_scaled, y_train)
y_pred = model.predict(X_test_scaled)

"""Importing joblib for hugging face"""

import joblib
joblib.dump(model, "model.joblib")
joblib.dump(scaler, "scaler.joblib")

"""Calculating R² score"""

R_squared = r2_score(y_test, y_pred)
print("R² score:", R_squared)

"""Calculating mean of R² score after cross validation"""

print(f"R² score after cross validation: {cross_val_score(model, X_train_scaled, y_train, cv=10).mean()}")

with open("requirements.txt", "w") as f:
    f.write("gradio\nscikit-learn\nnumpy\njoblib")

import zipfile

with zipfile.ZipFile("California_app.zip", "w") as zipf:
    zipf.write("model.joblib")
    zipf.write("scaler.joblib")
    zipf.write("requirements.txt")

from google.colab import files
files.download("California_app.zip")